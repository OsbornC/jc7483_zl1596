{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit-recognizer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (33600, 784))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8d10b5a26bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-8d10b5a26bb9>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mneural_net_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neural network initialization'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcall\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneural_net_calls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    116\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (33600, 784))"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "meta_file = pd.read_csv(\"./AutoKaggle - Metadata.csv\", encoding='cp1252',error_bad_lines=False)\n",
    "arrOfRows = [64,360,239,316,515,518, 523, 451]\n",
    "nlp_rows = [239]\n",
    "tabular_rows = [64,360,316,515,518]\n",
    "row = 451\n",
    "competition_name = meta_file['name'].loc[row]\n",
    "print(meta_file['name'].loc[row])\n",
    "dir_name = \"./\" + competition_name \n",
    "train_file = dir_name + \"/data/train.csv\"\n",
    "row_file = dir_name + \"/submission/row.csv\"\n",
    "\n",
    "meta = pd.read_csv(row_file)\n",
    "def preprocessing(row):\n",
    "   \n",
    "    train = pd.read_csv(train_file)\n",
    "    check_pred = False\n",
    "    train_X = ''\n",
    "    train_Y = ''\n",
    "    test = None\n",
    "    auxiliary = []\n",
    "    if meta['name'].loc[0] == 'kobe-bryant-shot-selection':\n",
    "        train = pd.read_csv(\"./kobe-bryant-shot-selection/data/data.csv\")\n",
    "        check_pred = False\n",
    "    elif meta['name'].loc[0] == 'mercedes-benz-greener-manufacturing':\n",
    "        train = pd.read_csv(\"./mercedes-benz-greener-manufacturing/data/train.csv\")\n",
    "        test = pd.read_csv(\"./mercedes-benz-greener-manufacturing/data/test.csv\")\n",
    "      \n",
    "\n",
    "    if meta['name'].loc[0] == 'uciml_sms-spam-collection-dataset':\n",
    "        row = pd.read_csv(\"./uciml_sms-spam-collection-dataset/submission/row.csv\", encoding='cp1252')\n",
    "        sms = train\n",
    "        row_prepro = row['preprocessing function call'][0]\n",
    "        prepro_ls = eval(row_prepro)\n",
    "        sms = eval(prepro_ls[0])\n",
    "        train = eval(prepro_ls[1])\n",
    "        return train\n",
    "    else:\n",
    "        target_name = str(meta['targetName'].loc[0])\n",
    "        train_Y = train[[target_name]]\n",
    "        train = train.drop(columns=target_name)\n",
    "        if type(meta['auxiliaryDataURL'].loc[0]) is str:\n",
    "            auxiliary_calls = eval(meta['auxiliaryDataURL'].loc[0])\n",
    "            for call in auxiliary_calls:\n",
    "                auxi = call\n",
    "                auxiliary.append(pd.read_csv(\"./\" + meta['name'].loc[0] + \"/auxiliary_data/\" + auxi + \".csv\"))\n",
    "        if type(meta['auxiliary function calls'].loc[0]) is str:\n",
    "            auxiliary_functions = eval(meta['auxiliary function calls'].loc[0])\n",
    "            for call in auxiliary_functions:\n",
    "                exec(call)\n",
    "        if type(meta['test set'].loc[0]) is str:\n",
    "            row_file = dir_name + \"/data/test.csv\"\n",
    "            test = pd.read_csv(row_file, encoding='cp1252', error_bad_lines=False)\n",
    "        if type(meta['preprocessing function call'].loc[0]) is str:\n",
    "            preprocessing_calls = eval(meta['preprocessing function call'].loc[0])\n",
    "            for call in preprocessing_calls:\n",
    "                exec(call)\n",
    "        train = train.dropna()\n",
    "        if type(meta[\"unwanted column\"].loc[0]) is str:  # check if there's unwanted column\n",
    "            column_list = eval(meta[\"unwanted column\"].loc[0])\n",
    "            train = train.drop(column_list,axis=1)\n",
    "        if type(meta[\"numeric column\"].loc[0]) is str:\n",
    "            numeric=eval(meta[\"numeric column\"].loc[0])\n",
    "\n",
    "        if type(meta['augmentation function calls'].loc[0]) is str:\n",
    "            augmentation_calls = eval(meta['augmentation function calls'].loc[0])\n",
    "            for call in augmentation_calls:\n",
    "                exec(call)\n",
    "                \n",
    "        for c in train.columns:\n",
    "            if train[c].dtype == 'object':    # deal with text\n",
    "                lbl = LabelEncoder() \n",
    "                if check_pred:\n",
    "                    lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "                    train[c] = lbl.transform(list(train[c].values))\n",
    "                    test[c] = lbl.transform(list(test[c].values))\n",
    "                else:\n",
    "                    lbl.fit(list(train[c].values))\n",
    "                    train[c] = lbl.transform(list(train[c].values))\n",
    "\n",
    "#         train_X,test_X,train_Y,test_Y = train_test_split(train, train_Y, test_size=0.2)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(train, train_Y, test_size=0.2)\n",
    "        model = Sequential()\n",
    "        if type(meta['neural network initialization'].loc[0]) is str:\n",
    "            neural_net_calls = eval(meta['neural network initialization'].loc[0])\n",
    "            for call in neural_net_calls:\n",
    "                exec(call)\n",
    "        if check_pred:\n",
    "            return train_X, train_Y, test_X, test_Y, pred_X\n",
    "        else:\n",
    "            return train_X, train_Y, test_X, test_Y,None#         if check_pred:\n",
    "\n",
    "\n",
    "preprocessing(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return \" \".join(text)\n",
    "\n",
    "def feature_extraction(row, X_train, X_test,X_pred):\n",
    "    if meta['name'].loc[0] == 'uciml_sms-spam-collection-dataset':\n",
    "        rowcsv = pd.read_csv(\"./uciml_sms-spam-collection-dataset/submission/row.csv\")\n",
    "        row_extract = rowcsv['featureExtractor function call'].loc[0]\n",
    "        sms = X_train\n",
    "        extract = eval(row_extract)\n",
    "        sms['message'] = eval(extract[0])\n",
    "        sms['message'] = eval(extract[1])\n",
    "        text_feat = sms['message'].apply(str).copy()\n",
    "        text_feat = eval(extract[2])\n",
    "        vectorizer = eval(extract[3])\n",
    "        features = eval(extract[4])\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, sms['label'], test_size=0.3)\n",
    "        return features_train, features_test, labels_train, labels_test\n",
    "    else:\n",
    "        if type(meta[\"featureExtractor function call\"].loc[0]) is not str:\n",
    "            print('not func')\n",
    "            return X_train,X_test,X_pred\n",
    "        extraction_function_calls = str(row_data[\"function call feature extraction\"].loc[0])\n",
    "        extraction_function_calls = extraction_function_calls.split(\",\")\n",
    "        extraction_funtion_param = eval(row_data[\"function parameters feature extraction\"].loc[0])\n",
    "        function_nums = len(extraction_function_calls)\n",
    "        for i in range(function_nums):\n",
    "            str1 = extraction_function_calls[i]\n",
    "            str2 = extraction_funtion_param[i]\n",
    "            l_str = str1.split(\"(\")\n",
    "            l_str.insert(1,\"(\"+str2)\n",
    "            str_call = ''\n",
    "            str_call = str_call.join(l_str)\n",
    "            str_call = 'extractor' + '=' + str_call\n",
    "            exec(str_call, globals(), globals())\n",
    "            extracted_train = extractor.fit_transform(X_train)\n",
    "            n_comp = extracted_train.shape[1]\n",
    "            for j in range(0, n_comp):\n",
    "                X_train['extractor'+ str(i)+\"_\"+str(j)] = extracted_train[:, j]\n",
    "            if X_test is not None:\n",
    "                extracted_test = extractor.fit_transform(X_test)\n",
    "                for j in range(0, n_comp):\n",
    "                    X_test['extractor'+ str(i)+\"_\"+str(j)] = extracted_test[:, j]\n",
    "                return X_train,X_test\n",
    "            else:\n",
    "                return X_train,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(row,X_train,X_test,Y_train, Y_test):\n",
    "    if row in nlp_rows:\n",
    "        rowcsv = pd.read_csv(\"./uciml_sms-spam-collection-dataset/submission/row.csv\")\n",
    "        row_extract = eval(rowcsv['estimator1 function call'].loc[0])\n",
    "        mnb = eval(row_extract[0])\n",
    "        eval(row_extract[1])\n",
    "        pred = eval(row_extract[2])\n",
    "        if rowcsv['performanceMetric'].loc[0] == 'accuracy':\n",
    "            return accuracy_score(Y_test, pred)\n",
    "    else:\n",
    "        estimation_function_calls = eval(meta[\"estimator1 function call\"].loc[0])\n",
    "        print(estimation_function_calls)\n",
    "        if len(estimation_function_calls) == 1:\n",
    "            if type(meta['neural network initialization'].loc[0]) is str:\n",
    "                neural_net_calls = eval(meta['neural network initialization'].loc[0])\n",
    "                for call in neural_net_calls:\n",
    "                    exec(call)\n",
    "            else:\n",
    "                str_call = estimation_function_calls[0]\n",
    "                str_call = 'estimator' + '=' + str_call\n",
    "                exec(str_call,globals(),globals())\n",
    "                estimator.fit(X_train,Y_train)\n",
    "                Y_pred = estimator.predict(X_test)\n",
    "                if meta[\"taskType\"].loc[0] == 'classification':\n",
    "                    print(accuracy_score(Y_test,Y_pred))\n",
    "                if meta[\"taskType\"].loc[0] == 'regression':\n",
    "                    print(\"Mean Squared Error is: \", mean_squared_error(Y_test,Y_pred))\n",
    "        else:\n",
    "            estimators = []\n",
    "            n_estimators = len(estimation_function_calls)\n",
    "            for i in range(n_estimators):\n",
    "                str1 = extraction_function_calls\n",
    "                l_str = str1.split(\"(\")\n",
    "                l_str.insert(1,\"(\"+str2)\n",
    "                str_call = ''\n",
    "                str_call = str_call.join(l_str)\n",
    "                str_call = 'estimator' + '=' + str_call\n",
    "                print(l_str)\n",
    "                print(str_call)\n",
    "                exec(str_call)\n",
    "                estimators.append(estimator)\n",
    "                postprocessing(estimators,stack = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if row in nlp_rows:\n",
    "    train_set = preprocessing(row)\n",
    "    X_train, X_test, Y_train, Y_test = feature_extraction(row, train_set, None)\n",
    "    Y_pred = estimation(row, X_train, X_test, Y_train, Y_test)\n",
    "    print(Y_pred)\n",
    "if row in tabular_rows:\n",
    "    X_train,Y_train,X_test,Y_test,X_pred = preprocessing(row)\n",
    "    X_train,X_test,X_pred = feature_extraction(row,X_train,X_test,X_pred)\n",
    "    estimation(row,X_train,X_test,Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if meta['name'].loc[row] == 'uciml_sms-spam-collection-dataset':\n",
    "#     train_set = preprocessing(row)\n",
    "#     X_train, X_test, Y_train, Y_test = feature_extraction(row, train_set, None)\n",
    "#     Y_pred = estimation(row, X_train, X_test, Y_train, Y_test)\n",
    "#     print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(estimators,stack):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(\"Use\", end - start, \"seconds to run this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['test set'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = preprocessing(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y, pred = preprocessing(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>5482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214484</th>\n",
       "      <td>3180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160970</th>\n",
       "      <td>6859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382268</th>\n",
       "      <td>9089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505530</th>\n",
       "      <td>9029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654252</th>\n",
       "      <td>9640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248423</th>\n",
       "      <td>9473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955511</th>\n",
       "      <td>5107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701507</th>\n",
       "      <td>5154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799746</th>\n",
       "      <td>6676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9219</th>\n",
       "      <td>7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450653</th>\n",
       "      <td>4519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569100</th>\n",
       "      <td>4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538504</th>\n",
       "      <td>8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238330</th>\n",
       "      <td>6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448288</th>\n",
       "      <td>3674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275012</th>\n",
       "      <td>8392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920429</th>\n",
       "      <td>7868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756089</th>\n",
       "      <td>7339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590718</th>\n",
       "      <td>2934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717174</th>\n",
       "      <td>6094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369897</th>\n",
       "      <td>8357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304488</th>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156288</th>\n",
       "      <td>7170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860195</th>\n",
       "      <td>4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384959</th>\n",
       "      <td>5014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255713</th>\n",
       "      <td>3809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908822</th>\n",
       "      <td>6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151023</th>\n",
       "      <td>5330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428575</th>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12283</th>\n",
       "      <td>6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996455</th>\n",
       "      <td>8229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459034</th>\n",
       "      <td>4425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41387</th>\n",
       "      <td>5220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635491</th>\n",
       "      <td>4594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454644</th>\n",
       "      <td>9424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930320</th>\n",
       "      <td>6494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46455</th>\n",
       "      <td>7947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199574</th>\n",
       "      <td>6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679451</th>\n",
       "      <td>5971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187623</th>\n",
       "      <td>6987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542713</th>\n",
       "      <td>9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634074</th>\n",
       "      <td>3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812158</th>\n",
       "      <td>6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844017</th>\n",
       "      <td>5154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574722</th>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841666</th>\n",
       "      <td>5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419045</th>\n",
       "      <td>3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598249</th>\n",
       "      <td>5821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265042</th>\n",
       "      <td>12433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718755</th>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944525</th>\n",
       "      <td>11595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693100</th>\n",
       "      <td>4407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717134</th>\n",
       "      <td>9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24426</th>\n",
       "      <td>4699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572833</th>\n",
       "      <td>11020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819816</th>\n",
       "      <td>3469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202630</th>\n",
       "      <td>4443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>675470 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sales\n",
       "8529     5482\n",
       "214484   3180\n",
       "160970   6859\n",
       "382268   9089\n",
       "505530   9029\n",
       "654252   9640\n",
       "248423   9473\n",
       "955511   5107\n",
       "701507   5154\n",
       "799746   6676\n",
       "9219     7151\n",
       "450653   4519\n",
       "569100   4721\n",
       "538504   8304\n",
       "238330   6850\n",
       "448288   3674\n",
       "275012   8392\n",
       "920429   7868\n",
       "756089   7339\n",
       "590718   2934\n",
       "717174   6094\n",
       "369897   8357\n",
       "304488   4821\n",
       "156288   7170\n",
       "860195   4616\n",
       "384959   5014\n",
       "255713   3809\n",
       "908822   6866\n",
       "151023   5330\n",
       "8090     3081\n",
       "...       ...\n",
       "428575   3608\n",
       "12283    6635\n",
       "996455   8229\n",
       "459034   4425\n",
       "41387    5220\n",
       "635491   4594\n",
       "454644   9424\n",
       "930320   6494\n",
       "522340   6395\n",
       "46455    7947\n",
       "199574   6710\n",
       "679451   5971\n",
       "187623   6987\n",
       "542713   9853\n",
       "634074   3665\n",
       "812158   6775\n",
       "844017   5154\n",
       "574722   4767\n",
       "841666   5342\n",
       "419045   3176\n",
       "598249   5821\n",
       "265042  12433\n",
       "718755   5457\n",
       "944525  11595\n",
       "693100   4407\n",
       "717134   9872\n",
       "24426    4699\n",
       "572833  11020\n",
       "819816   3469\n",
       "202630   4443\n",
       "\n",
       "[675470 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Osborn/anaconda3/lib/python2.7/site-packages/ipykernel_launcher.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean Squared Error is: ', 3585169.497040621)\n"
     ]
    }
   ],
   "source": [
    "estimation(row,train_X, test_X, train_Y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Use', 53.83630609512329, 'seconds to run this.')\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Use\", end - start, \"seconds to run this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/Osborn/anaconda3/envs/myTensorflow:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "absl-py                   0.7.1                    pypi_0    pypi\r\n",
      "appnope                   0.1.0            py35hd172556_0  \r\n",
      "astor                     0.7.1                    pypi_0    pypi\r\n",
      "attrs                     19.1.0                     py_0  \r\n",
      "automat                   0.7.0                    py35_0  \r\n",
      "backcall                  0.1.0                    py35_0  \r\n",
      "bleach                    2.1.4                    py35_0  \r\n",
      "ca-certificates           2019.1.23                     0    anaconda\r\n",
      "certifi                   2018.8.24                py35_1    anaconda\r\n",
      "chardet                   3.0.4                    pypi_0    pypi\r\n",
      "colorama                  0.4.1                    pypi_0    pypi\r\n",
      "constantly                15.1.0           py35h28b3542_0  \r\n",
      "cycler                    0.10.0                   pypi_0    pypi\r\n",
      "decorator                 4.4.0                      py_0  \r\n",
      "defusedxml                0.6.0                      py_0  \r\n",
      "entrypoints               0.2.3                    py35_2  \r\n",
      "future                    0.17.1                   pypi_0    pypi\r\n",
      "gast                      0.2.2                    pypi_0    pypi\r\n",
      "grpcio                    1.20.1                   pypi_0    pypi\r\n",
      "h2o                       3.24.0.2                 pypi_0    pypi\r\n",
      "h5py                      2.9.0                    pypi_0    pypi\r\n",
      "html5lib                  1.0.1                    py35_0  \r\n",
      "hyperlink                 19.0.0                     py_0  \r\n",
      "idna                      2.7                      py35_0  \r\n",
      "incremental               17.5.0                   py35_0  \r\n",
      "ipykernel                 4.10.0                   py35_0  \r\n",
      "ipython                   6.5.0                    py35_0  \r\n",
      "ipython_genutils          0.2.0            py35hf129286_0  \r\n",
      "jedi                      0.12.1                   py35_0  \r\n",
      "jinja2                    2.10                     py35_0  \r\n",
      "jsonschema                2.6.0            py35h2dd9e4b_0  \r\n",
      "jupyter_client            5.2.3                    py35_0  \r\n",
      "jupyter_core              4.4.0                    py35_0  \r\n",
      "keras                     2.2.4                    pypi_0    pypi\r\n",
      "keras-applications        1.0.7                    pypi_0    pypi\r\n",
      "keras-preprocessing       1.0.9                    pypi_0    pypi\r\n",
      "kiwisolver                1.1.0                    pypi_0    pypi\r\n",
      "libcxx                    4.0.1                hcfea43d_1  \r\n",
      "libcxxabi                 4.0.1                hcfea43d_1  \r\n",
      "libedit                   3.1.20181209         hb402a30_0  \r\n",
      "libffi                    3.2.1                h475c297_4  \r\n",
      "libsodium                 1.0.16               h3efe00b_0  \r\n",
      "markdown                  3.1                      pypi_0    pypi\r\n",
      "markupsafe                1.0              py35h1de35cc_1  \r\n",
      "matplotlib                3.0.3                    pypi_0    pypi\r\n",
      "mistune                   0.8.3            py35h1de35cc_1  \r\n",
      "mock                      3.0.3                    pypi_0    pypi\r\n",
      "nbconvert                 5.5.0                      py_0  \r\n",
      "nbformat                  4.4.0            py35h41c2038_0  \r\n",
      "ncurses                   6.1                  h0a44026_1  \r\n",
      "nltk                      3.4.1                    pypi_0    pypi\r\n",
      "notebook                  5.4.1                    py35_0  \r\n",
      "numpy                     1.16.3                   pypi_0    pypi\r\n",
      "openssl                   1.0.2r               h1de35cc_0    anaconda\r\n",
      "pandas                    0.24.2                   pypi_0    pypi\r\n",
      "pandoc                    2.2.3.2                       0  \r\n",
      "pandocfilters             1.4.2                    py35_1  \r\n",
      "parso                     0.4.0                      py_0  \r\n",
      "pexpect                   4.6.0                    py35_0  \r\n",
      "pickleshare               0.7.4            py35h9517181_0  \r\n",
      "pip                       10.0.1                   py35_0  \r\n",
      "prometheus_client         0.3.1            py35h28b3542_0  \r\n",
      "prompt_toolkit            1.0.15           py35h93950c5_0  \r\n",
      "protobuf                  3.7.1                    pypi_0    pypi\r\n",
      "ptyprocess                0.6.0                    py35_0  \r\n",
      "pygments                  2.2.0            py35h392a662_0  \r\n",
      "pyparsing                 2.4.0                    pypi_0    pypi\r\n",
      "python                    3.5.6                hc167b69_0  \r\n",
      "python-dateutil           2.7.3                    py35_0  \r\n",
      "pytz                      2019.1                   pypi_0    pypi\r\n",
      "pyyaml                    5.1                      pypi_0    pypi\r\n",
      "pyzmq                     17.1.2           py35h1de35cc_0    anaconda\r\n",
      "readline                  7.0                  h1de35cc_5  \r\n",
      "requests                  2.21.0                   pypi_0    pypi\r\n",
      "scikit-learn              0.20.3                   pypi_0    pypi\r\n",
      "scipy                     1.2.1                    pypi_0    pypi\r\n",
      "seaborn                   0.9.0                    pypi_0    pypi\r\n",
      "send2trash                1.5.0                    py35_0  \r\n",
      "setuptools                40.2.0                   py35_0  \r\n",
      "simplegeneric             0.8.1                    py35_2  \r\n",
      "six                       1.11.0                   py35_1  \r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "sns                       0.1                      pypi_0    pypi\r\n",
      "sqlite                    3.28.0               ha441bb4_0  \r\n",
      "tabulate                  0.8.3                    pypi_0    pypi\r\n",
      "tensorboard               1.13.1                   pypi_0    pypi\r\n",
      "tensorflow                1.13.1                   pypi_0    pypi\r\n",
      "tensorflow-estimator      1.13.0                   pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.8.1                    py35_1  \r\n",
      "testpath                  0.3.1            py35hf8009f4_0  \r\n",
      "tk                        8.6.8                ha441bb4_0  \r\n",
      "torch                     1.1.0                    pypi_0    pypi\r\n",
      "tornado                   5.1.1            py35h1de35cc_0  \r\n",
      "traitlets                 4.3.2            py35hd3d1486_0  \r\n",
      "twisted                   17.5.0                   py35_0  \r\n",
      "urllib3                   1.24.3                   pypi_0    pypi\r\n",
      "wcwidth                   0.1.7            py35hdd0c235_0  \r\n",
      "webencodings              0.5.1                    py35_1  \r\n",
      "werkzeug                  0.15.2                   pypi_0    pypi\r\n",
      "wheel                     0.31.1                   py35_0  \r\n",
      "xgboost                   0.82                     pypi_0    pypi\r\n",
      "xz                        5.2.4                h1de35cc_4  \r\n",
      "zeromq                    4.2.5                h0a44026_1    anaconda\r\n",
      "zlib                      1.2.11               h1de35cc_3  \r\n",
      "zope                      1.0                      py35_1  \r\n",
      "zope.interface            4.5.0            py35h1de35cc_0  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: failed\n",
      "\n",
      "UnavailableInvalidChannel: The channel is not accessible or is invalid.\n",
      "  channel name: lyken/simple\n",
      "  channel url: https://pypi.anaconda.org/lyken/simple\n",
      "  error code: 404\n",
      "\n",
      "You will need to adjust your conda configuration to proceed.\n",
      "Use `conda config --show channels` to view your configuration's current state,\n",
      "and use `conda config --show-sources` to view config file locations.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Osborn/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/torch/_C.cpython-35m-darwin.so, 9): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/Osborn/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/torch/lib/libshm.dylib\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Osborn/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/torch/_C.cpython-35m-darwin.so, 9): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/Osborn/anaconda3/envs/myTensorflow/lib/python3.5/site-packages/torch/lib/libshm.dylib\n  Reason: image not found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
