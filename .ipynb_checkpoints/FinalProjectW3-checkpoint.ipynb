{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA,TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection,SparseRandomProjection\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# import h2o\n",
    "# from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ghouls-goblins-and-ghosts-boo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     bone_length  rotting_flesh  hair_length  has_soul\n",
       " 333     0.168644       0.313009     0.443639  0.539800\n",
       " 19      0.524080       0.750988     0.524637  0.443358\n",
       " 121     0.339501       0.336981     0.492441  0.345592\n",
       " 282     0.406834       0.455310     0.287008  0.641681\n",
       " 139     0.416152       0.418087     0.802077  0.454922\n",
       " 29      0.304198       0.266904     0.527225  0.386713\n",
       " 290     0.417253       0.624973     0.328752  0.279668\n",
       " 104     0.252513       0.479093     0.658847  0.330915\n",
       " 190     0.308755       0.705034     0.643468  0.583750\n",
       " 256     0.588413       0.656242     0.835501  0.636101\n",
       " 331     0.361867       0.565680     0.419227  0.519361\n",
       " 65      0.609634       0.646037     0.243755  0.348240\n",
       " 267     0.374148       0.344590     0.636340  0.248143\n",
       " 316     0.421934       0.250401     0.851171  0.580753\n",
       " 173     0.327031       0.608481     0.310469  0.356699\n",
       " 200     0.566424       0.431110     0.684599  0.575277\n",
       " 214     0.469020       0.621063     0.641631  0.598485\n",
       " 284     0.761355       0.331480     0.861060  0.735897\n",
       " 70      0.315276       0.587053     0.446189  0.800853\n",
       " 155     0.559825       0.649088     0.759295  0.656943\n",
       " 143     0.369274       0.744830     0.653939  0.675961\n",
       " 328     0.396988       0.611109     0.507214  0.179642\n",
       " 321     0.187781       0.736491     0.344348  0.346306\n",
       " 349     0.502599       0.604174     0.617955  0.593545\n",
       " 238     0.654488       0.439392     0.621121  0.740199\n",
       " 251     0.160465       0.696646     0.408945  0.217147\n",
       " 210     0.439063       0.490515     0.654721  0.405319\n",
       " 100     0.471764       0.801465     0.230619  0.285067\n",
       " 15      0.500197       0.438418     0.532530  0.665522\n",
       " 186     0.208885       0.399537     0.421704  0.216800\n",
       " ..           ...            ...          ...       ...\n",
       " 273     0.515397       0.561786     0.528818  0.373502\n",
       " 362     0.377449       0.466158     0.497351  0.393305\n",
       " 194     0.465423       0.095687     0.406791  0.364341\n",
       " 220     0.168909       0.648866     0.303927  0.255440\n",
       " 347     0.332374       0.605206     0.299235  0.570073\n",
       " 96      0.341539       0.689139     0.313948  0.055464\n",
       " 188     0.452126       0.636626     0.162715  0.099904\n",
       " 320     0.342585       0.261752     0.582865  0.510331\n",
       " 112     0.532590       0.375698     0.553827  0.679403\n",
       " 180     0.340442       0.531701     0.428498  0.263063\n",
       " 102     0.318316       0.661752     0.476469  0.233136\n",
       " 311     0.444006       0.424189     0.549613  0.447517\n",
       " 277     0.184383       0.478937     0.374396  0.521730\n",
       " 351     0.552971       0.341187     0.644801  0.415394\n",
       " 80      0.518560       0.808514     0.323921  0.574505\n",
       " 287     0.479818       0.569762     0.721362  0.491938\n",
       " 97      0.365437       0.513115     0.468037  0.546090\n",
       " 352     0.496140       0.377488     0.647238  0.465689\n",
       " 253     0.427218       0.545423     0.639650  0.604801\n",
       " 116     0.365032       0.524358     0.328400  0.325906\n",
       " 218     0.390145       0.554114     0.551970  0.317077\n",
       " 115     0.480941       0.742555     0.329061  0.429933\n",
       " 330     0.511593       0.729360     0.492918  0.803195\n",
       " 247     0.269748       0.627138     0.195365  0.367902\n",
       " 138     0.351562       0.457490     0.547977  0.368370\n",
       " 28      0.411663       0.454075     0.408097  0.432921\n",
       " 236     0.451085       0.464508     0.505819  0.509010\n",
       " 295     0.630585       0.539712     0.305580  0.777520\n",
       " 222     0.250293       0.408878     0.456618  0.466024\n",
       " 98      0.431501       0.349555     0.468936  0.194413\n",
       " \n",
       " [296 rows x 4 columns],        type\n",
       " 333   Ghost\n",
       " 19    Ghost\n",
       " 121  Goblin\n",
       " 282   Ghoul\n",
       " 139   Ghoul\n",
       " 29   Goblin\n",
       " 290   Ghost\n",
       " 104  Goblin\n",
       " 190   Ghoul\n",
       " 256   Ghoul\n",
       " 331   Ghost\n",
       " 65    Ghost\n",
       " 267   Ghost\n",
       " 316   Ghoul\n",
       " 173   Ghost\n",
       " 200   Ghoul\n",
       " 214  Goblin\n",
       " 284   Ghoul\n",
       " 70    Ghoul\n",
       " 155   Ghoul\n",
       " 143  Goblin\n",
       " 328   Ghost\n",
       " 321   Ghost\n",
       " 349   Ghoul\n",
       " 238   Ghoul\n",
       " 251   Ghost\n",
       " 210  Goblin\n",
       " 100   Ghost\n",
       " 15    Ghoul\n",
       " 186   Ghost\n",
       " ..      ...\n",
       " 273   Ghoul\n",
       " 362  Goblin\n",
       " 194  Goblin\n",
       " 220   Ghost\n",
       " 347   Ghost\n",
       " 96    Ghost\n",
       " 188   Ghost\n",
       " 320  Goblin\n",
       " 112   Ghoul\n",
       " 180   Ghost\n",
       " 102   Ghost\n",
       " 311  Goblin\n",
       " 277   Ghost\n",
       " 351  Goblin\n",
       " 80    Ghost\n",
       " 287   Ghoul\n",
       " 97   Goblin\n",
       " 352   Ghoul\n",
       " 253  Goblin\n",
       " 116   Ghost\n",
       " 218   Ghost\n",
       " 115   Ghost\n",
       " 330   Ghoul\n",
       " 247   Ghost\n",
       " 138  Goblin\n",
       " 28   Goblin\n",
       " 236  Goblin\n",
       " 295   Ghoul\n",
       " 222  Goblin\n",
       " 98   Goblin\n",
       " \n",
       " [296 rows x 1 columns],      bone_length  rotting_flesh  hair_length  has_soul\n",
       " 66      0.424969       0.240299     0.338678  0.088924\n",
       " 353     0.362567       0.639753     0.536248  0.427678\n",
       " 343     0.624388       0.661235     0.574458  0.642300\n",
       " 367     0.331936       0.564836     0.539216  0.551471\n",
       " 299     0.354047       0.540752     0.571210  0.243775\n",
       " 128     0.444009       0.416513     0.718762  0.508057\n",
       " 309     0.337804       0.378093     0.694287  0.543536\n",
       " 25      0.229010       0.567313     0.373743  0.329636\n",
       " 14      0.513387       0.301345     0.745676  0.545792\n",
       " 168     0.403995       0.682687     0.372529  0.499520\n",
       " 4       0.566117       0.875862     0.418594  0.636438\n",
       " 34      0.558196       0.580363     0.772734  0.370740\n",
       " 202     0.421721       0.320303     0.427802  0.533696\n",
       " 159     0.192909       0.504090     0.383679  0.307534\n",
       " 78      0.631327       0.411749     0.707609  0.769455\n",
       " 163     0.630471       0.581029     0.647251  0.505213\n",
       " 6       0.399331       0.568952     0.618391  0.467901\n",
       " 246     0.184181       0.631607     0.453163  0.431742\n",
       " 356     0.445547       0.241139     0.558614  0.399302\n",
       " 237     0.523789       0.657317     0.818979  0.624504\n",
       " 157     0.406880       0.464490     0.538146  0.600827\n",
       " 242     0.367799       0.637446     0.416354  0.415930\n",
       " 26      0.388501       0.342306     0.669627  0.538649\n",
       " 105     0.519827       0.568441     0.434171  0.351851\n",
       " 225     0.518231       0.494491     0.545443  0.600393\n",
       " 258     0.586227       0.464284     0.599774  0.856757\n",
       " 363     0.507583       0.799623     0.334520  0.344403\n",
       " 40      0.415110       0.434616     0.707469  0.526319\n",
       " 301     0.577809       0.500339     0.756629  0.854949\n",
       " 243     0.323613       0.431312     0.205097  0.257617\n",
       " ..           ...            ...          ...       ...\n",
       " 289     0.493395       0.501552     0.660367  0.605897\n",
       " 150     0.421217       0.549165     0.474128  0.425993\n",
       " 114     0.489132       0.481304     0.482691  0.460081\n",
       " 181     0.306044       0.531350     0.266590  0.307630\n",
       " 57      0.515275       0.582627     0.568721  0.534079\n",
       " 272     0.390669       0.841120     0.195072  0.307668\n",
       " 325     0.571056       0.729873     0.421166  0.785423\n",
       " 191     0.471201       0.568542     0.515442  0.388791\n",
       " 370     0.670200       0.768469     0.737274  0.608384\n",
       " 131     0.609161       0.717767     0.658848  0.466372\n",
       " 111     0.476730       0.242420     0.294214  0.317795\n",
       " 296     0.440998       0.234051     0.576912  0.509368\n",
       " 106     0.450759       0.542649     0.795207  0.739429\n",
       " 216     0.505597       0.451094     0.683994  0.792072\n",
       " 346     0.346283       0.158742     0.714987  0.322676\n",
       " 199     0.415142       0.620149     0.313793  0.418053\n",
       " 101     0.207874       0.545294     0.357987  0.484055\n",
       " 336     0.279875       0.656420     0.629068  0.292060\n",
       " 45      0.287193       0.530852     0.466725  0.299993\n",
       " 137     0.297148       0.531544     0.312002  0.382700\n",
       " 148     0.528987       0.496139     0.716997  0.332592\n",
       " 314     0.417300       0.377595     0.541834  0.349087\n",
       " 135     0.584177       0.445350     0.714323  0.650264\n",
       " 339     0.488632       0.548473     0.598621  0.544566\n",
       " 206     0.357145       0.489931     0.698190  0.753687\n",
       " 12      0.390712       0.335069     0.556109  0.784217\n",
       " 59      0.512677       0.417474     0.678072  0.796332\n",
       " 141     0.384235       0.393451     0.353746  0.490884\n",
       " 72      0.348991       0.564233     0.481190  0.177172\n",
       " 126     0.411353       0.492621     0.437745  0.276163\n",
       " \n",
       " [75 rows x 4 columns],        type\n",
       " 66    Ghost\n",
       " 353  Goblin\n",
       " 343  Goblin\n",
       " 367   Ghost\n",
       " 299   Ghost\n",
       " 128   Ghoul\n",
       " 309  Goblin\n",
       " 25    Ghost\n",
       " 14   Goblin\n",
       " 168   Ghost\n",
       " 4     Ghost\n",
       " 34    Ghoul\n",
       " 202   Ghoul\n",
       " 159   Ghost\n",
       " 78    Ghoul\n",
       " 163   Ghoul\n",
       " 6    Goblin\n",
       " 246   Ghost\n",
       " 356  Goblin\n",
       " 237   Ghoul\n",
       " 157  Goblin\n",
       " 242   Ghost\n",
       " 26   Goblin\n",
       " 105   Ghost\n",
       " 225   Ghoul\n",
       " 258   Ghoul\n",
       " 363   Ghost\n",
       " 40    Ghoul\n",
       " 301  Goblin\n",
       " 243   Ghost\n",
       " ..      ...\n",
       " 289   Ghoul\n",
       " 150   Ghost\n",
       " 114  Goblin\n",
       " 181   Ghost\n",
       " 57   Goblin\n",
       " 272   Ghost\n",
       " 325   Ghoul\n",
       " 191  Goblin\n",
       " 370   Ghoul\n",
       " 131   Ghoul\n",
       " 111  Goblin\n",
       " 296  Goblin\n",
       " 106   Ghoul\n",
       " 216   Ghoul\n",
       " 346  Goblin\n",
       " 199   Ghost\n",
       " 101   Ghost\n",
       " 336   Ghost\n",
       " 45   Goblin\n",
       " 137  Goblin\n",
       " 148  Goblin\n",
       " 314  Goblin\n",
       " 135   Ghoul\n",
       " 339   Ghoul\n",
       " 206   Ghoul\n",
       " 12    Ghoul\n",
       " 59    Ghoul\n",
       " 141  Goblin\n",
       " 72    Ghost\n",
       " 126   Ghost\n",
       " \n",
       " [75 rows x 1 columns], None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical  # convert to one-hot-encoding\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "meta_file = pd.read_csv(\"./AutoKaggle - Metadata.csv\",\n",
    "                        encoding='cp1252', error_bad_lines=False)\n",
    "arrOfRows = [64, 360, 239, 316, 515, 518, 523, 451]\n",
    "nlp_rows = [239]\n",
    "tabular_rows = [64, 360, 316, 515, 518,535]\n",
    "row = 535\n",
    "competition_name = meta_file['name'].loc[row]\n",
    "print(meta_file['name'].loc[row])\n",
    "dir_name = \"./\" + competition_name\n",
    "train_file = dir_name + \"/data/train.csv\"\n",
    "row_file = dir_name + \"/submission/row.csv\"\n",
    "\n",
    "meta = pd.read_csv(row_file)\n",
    "\n",
    "\n",
    "def preprocessing(row):\n",
    "\n",
    "    train = pd.read_csv(train_file)\n",
    "    check_pred = False\n",
    "    train_X = ''\n",
    "    train_Y = ''\n",
    "    test = None\n",
    "    auxiliary = []\n",
    "    if meta['name'].loc[0] == 'kobe-bryant-shot-selection':\n",
    "        train = pd.read_csv(\"./kobe-bryant-shot-selection/data/data.csv\")\n",
    "        check_pred = False\n",
    "    elif meta['name'].loc[0] == 'mercedes-benz-greener-manufacturing':\n",
    "        train = pd.read_csv(\n",
    "            \"./mercedes-benz-greener-manufacturing/data/train.csv\")\n",
    "        test = pd.read_csv(\n",
    "            \"./mercedes-benz-greener-manufacturing/data/test.csv\")\n",
    "\n",
    "    if meta['name'].loc[0] == 'uciml_sms-spam-collection-dataset':\n",
    "        row = pd.read_csv(\n",
    "            \"./uciml_sms-spam-collection-dataset/submission/row.csv\", encoding='cp1252')\n",
    "        sms = train\n",
    "        row_prepro = row['preprocessing function call'][0]\n",
    "        prepro_ls = eval(row_prepro)\n",
    "        sms = eval(prepro_ls[0])\n",
    "        train = eval(prepro_ls[1])\n",
    "        return train\n",
    "    else:\n",
    "        target_name = str(meta['targetName'].loc[0])\n",
    "        train_Y = train[[target_name]]\n",
    "        train = train.drop(columns=target_name)\n",
    "        if type(meta['auxiliaryDataURL'].loc[0]) is str:\n",
    "            auxiliary_calls = eval(meta['auxiliaryDataURL'].loc[0])\n",
    "            for call in auxiliary_calls:\n",
    "                auxi = call\n",
    "                auxiliary.append(pd.read_csv(\n",
    "                    \"./\" + meta['name'].loc[0] + \"/auxiliary_data/\" + auxi + \".csv\"))\n",
    "        if type(meta['auxiliary function calls'].loc[0]) is str:\n",
    "            auxiliary_functions = eval(meta['auxiliary function calls'].loc[0])\n",
    "            for call in auxiliary_functions:\n",
    "                exec(call)\n",
    "        if type(meta['test set'].loc[0]) is str:\n",
    "            row_file = dir_name + \"/data/test.csv\"\n",
    "            test = pd.read_csv(row_file, encoding='cp1252',\n",
    "                               error_bad_lines=False)\n",
    "        if type(meta['preprocessing function call'].loc[0]) is str:\n",
    "            preprocessing_calls = eval(\n",
    "                meta['preprocessing function call'].loc[0])\n",
    "            for call in preprocessing_calls:\n",
    "                exec(call)\n",
    "        train = train.dropna()\n",
    "        if type(meta[\"unwanted column\"].loc[0]) is str:  # check if there's unwanted column\n",
    "            column_list = eval(meta[\"unwanted column\"].loc[0])\n",
    "            train = train.drop(column_list, axis=1)\n",
    "        if type(meta[\"numeric column\"].loc[0]) is str:\n",
    "            numeric = eval(meta[\"numeric column\"].loc[0])\n",
    "\n",
    "        if type(meta['augmentation function calls'].loc[0]) is str:\n",
    "            augmentation_calls = eval(\n",
    "                meta['augmentation function calls'].loc[0])\n",
    "            for call in augmentation_calls:\n",
    "                exec(call)\n",
    "\n",
    "        for c in train.columns:\n",
    "            if train[c].dtype == 'object':    # deal with text\n",
    "                lbl = LabelEncoder()\n",
    "                if check_pred:\n",
    "                    lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "                    train[c] = lbl.transform(list(train[c].values))\n",
    "                    test[c] = lbl.transform(list(test[c].values))\n",
    "                else:\n",
    "                    lbl.fit(list(train[c].values))\n",
    "                    train[c] = lbl.transform(list(train[c].values))\n",
    "\n",
    "        train_X,test_X,train_Y,test_Y = train_test_split(train, train_Y, test_size=0.2)\n",
    "\n",
    "        if check_pred:\n",
    "            return train_X, train_Y, test_X, test_Y, pred_X\n",
    "        else:\n",
    "            return train_X, train_Y, test_X, test_Y, None  # if check_pred:\n",
    "\n",
    "\n",
    "preprocessing(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = [word for word in text.split() if word.lower()\n",
    "            not in stopwords.words('english')]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "def feature_extraction(row, X_train, X_test, X_pred):\n",
    "    if meta['name'].loc[0] == 'uciml_sms-spam-collection-dataset':\n",
    "        rowcsv = pd.read_csv(\n",
    "            \"./uciml_sms-spam-collection-dataset/submission/row.csv\")\n",
    "        row_extract = rowcsv['featureExtractor function call'].loc[0]\n",
    "        sms = X_train\n",
    "        extract = eval(row_extract)\n",
    "        sms['message'] = eval(extract[0])\n",
    "        sms['message'] = eval(extract[1])\n",
    "        text_feat = sms['message'].apply(str).copy()\n",
    "        text_feat = eval(extract[2])\n",
    "        vectorizer = eval(extract[3])\n",
    "        features = eval(extract[4])\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "            features, sms['label'], test_size=0.3)\n",
    "        return features_train, features_test, labels_train, labels_test\n",
    "    else:\n",
    "        if type(meta[\"featureExtractor function call\"].loc[0]) is not str:\n",
    "            print('not func')\n",
    "            return X_train, X_test, X_pred\n",
    "        extraction_function_calls = str(\n",
    "            row_data[\"function call feature extraction\"].loc[0])\n",
    "        extraction_function_calls = extraction_function_calls.split(\",\")\n",
    "        extraction_funtion_param = eval(\n",
    "            row_data[\"function parameters feature extraction\"].loc[0])\n",
    "        function_nums = len(extraction_function_calls)\n",
    "        for i in range(function_nums):\n",
    "            str1 = extraction_function_calls[i]\n",
    "            str2 = extraction_funtion_param[i]\n",
    "            l_str = str1.split(\"(\")\n",
    "            l_str.insert(1, \"(\"+str2)\n",
    "            str_call = ''\n",
    "            str_call = str_call.join(l_str)\n",
    "            str_call = 'extractor' + '=' + str_call\n",
    "            exec(str_call, globals(), globals())\n",
    "            extracted_train = extractor.fit_transform(X_train)\n",
    "            n_comp = extracted_train.shape[1]\n",
    "            for j in range(0, n_comp):\n",
    "                X_train['extractor' + str(i)+\"_\"+str(j)\n",
    "                        ] = extracted_train[:, j]\n",
    "            if X_test is not None:\n",
    "                extracted_test = extractor.fit_transform(X_test)\n",
    "                for j in range(0, n_comp):\n",
    "                    X_test['extractor' + str(i)+\"_\" +\n",
    "                           str(j)] = extracted_test[:, j]\n",
    "                return X_train, X_test\n",
    "            else:\n",
    "                return X_train, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(row, X_train, X_test, Y_train, Y_test):\n",
    "    if row in nlp_rows:\n",
    "        rowcsv = pd.read_csv(\n",
    "            \"./uciml_sms-spam-collection-dataset/submission/row.csv\")\n",
    "        row_extract = eval(rowcsv['estimator1 function call'].loc[0])\n",
    "        mnb = eval(row_extract[0])\n",
    "        eval(row_extract[1])\n",
    "        pred = eval(row_extract[2])\n",
    "        if rowcsv['performanceMetric'].loc[0] == 'accuracy':\n",
    "            return accuracy_score(Y_test, pred)\n",
    "    else:\n",
    "        estimation_function_calls = eval(\n",
    "            meta[\"estimator1 function call\"].loc[0])\n",
    "        print(estimation_function_calls)\n",
    "        if len(estimation_function_calls) == 1:\n",
    "            if type(meta['neural network initialization'].loc[0]) is str:\n",
    "                neural_net_calls = eval(\n",
    "                    meta['neural network initialization'].loc[0])\n",
    "                for call in neural_net_calls:\n",
    "                    exec(call)\n",
    "            else:\n",
    "                str_call = estimation_function_calls[0]\n",
    "                str_call = 'estimator' + '=' + str_call\n",
    "                exec(str_call, globals(), globals())\n",
    "                estimator.fit(X_train, Y_train)\n",
    "                Y_pred = estimator.predict(X_test)\n",
    "                if meta[\"taskType\"].loc[0] == 'classification':\n",
    "                    print(accuracy_score(Y_test, Y_pred))\n",
    "                if meta[\"taskType\"].loc[0] == 'regression':\n",
    "                    print(\"Mean Squared Error is: \",\n",
    "                          mean_squared_error(Y_test, Y_pred))\n",
    "        else:\n",
    "            estimators = []\n",
    "            n_estimators = len(estimation_function_calls)\n",
    "            for i in range(n_estimators):\n",
    "                str1 = extraction_function_calls\n",
    "                l_str = str1.split(\"(\")\n",
    "                l_str.insert(1, \"(\"+str2)\n",
    "                str_call = ''\n",
    "                str_call = str_call.join(l_str)\n",
    "                str_call = 'estimator' + '=' + str_call\n",
    "                print(l_str)\n",
    "                print(str_call)\n",
    "                exec(str_call)\n",
    "                estimators.append(estimator)\n",
    "                postprocessing(estimators, stack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not func\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "source code string cannot contain null bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-77af7e7e9a17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mestimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-c0738007b816>\u001b[0m in \u001b[0;36mestimation\u001b[1;34m(row, X_train, X_test, Y_train, Y_test)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         estimation_function_calls = eval(\n\u001b[1;32m---> 13\u001b[1;33m             meta[\"estimator1 function call\"].loc[0])\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimation_function_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimation_function_calls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: source code string cannot contain null bytes"
     ]
    }
   ],
   "source": [
    "if row in nlp_rows:\n",
    "    train_set = preprocessing(row)\n",
    "    X_train, X_test, Y_train, Y_test = feature_extraction(row, train_set, None)\n",
    "    Y_pred = estimation(row, X_train, X_test, Y_train, Y_test)\n",
    "    print(Y_pred)\n",
    "\n",
    "\n",
    "if row in tabular_rows:\n",
    "    X_train, Y_train, X_test, Y_test, X_pred = preprocessing(row)\n",
    "    X_train, X_test, X_pred = feature_extraction(row, X_train, X_test, X_pred)\n",
    "    estimation(row, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if meta['name'].loc[row] == 'uciml_sms-spam-collection-dataset':\n",
    "#     train_set = preprocessing(row)\n",
    "#     X_train, X_test, Y_train, Y_test = feature_extraction(row, train_set, None)\n",
    "#     Y_pred = estimation(row, X_train, X_test, Y_train, Y_test)\n",
    "#     print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(estimators,stack):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 1.7716145515441895 seconds to run this.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Use\", end - start, \"seconds to run this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ca4819f8408c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mestimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "estimation(row,train_X, test_X, train_Y, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 3.626020669937134 seconds to run this.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Use\", end - start, \"seconds to run this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
