,NetId,name,URL,endDate,dataSize,table,image,audio,video,data type,text/csv,text/json,text/tab-separated-values,image/bmp,image/jpeg,image/png,image/tiff,audio/x-wav,audio/x-aiff,video/mp4,data format,"columns [index;name;type;...] for type use categorical, numerical, string, integer, dateTime etc",augmented dataset URL,taskType,taskSubType,outputType,targetIndex,targetName,rawData (non csv),rawDataIndex,problemDescription,preprocessing,preprocessing function call,featureExtractor,featureExtractor function call,featureSelector,featureSelector function call,sklearn,xgboost,keras,tensorflow,lightgbm,Libraries,estimators (all of them),estimator1,estimator1 function call,estimator2,estimator2 function call,estimator3,estimator3 function call,postprocessing,postprocessing function call,performanceMetric,crossValidationPerformance,codeURIRunningTimeSecondsTesting,codeURIRunningTimeSecondsTraining,WellWrittenCodeDocRating0-5,WellWrittenCodeRating0-5,codeURI,codeYear,codeMonth,codeAuthor,codeCountry,GenericUnivariateSelect,SelectPercentile,SelectKBest,SelectFpr,SelectFdr,SelectFromModel,SelectFwe,RFE,RFECV,VarianceThreshold,chi2,f_classif,f_regression,mutual_info_classif,mutual_info_regression,KNeighborsClassifier,KNeighborsRegressor,SGDClassifier,LinearRegression,LogisticRegression,Ridge,BayesianRidge,Lasso,SGDRegressor,DecisionTreeClassifier,DecisionTreeRegressor,LinearSVC,SVC,LinearSVR,RandomForestClassifier,GradientBoostingClassifier,RandomForestRegressor,GradientBoostingRegressor,MLPClassifier,XGBClassifier,XGBRegressor,CNN,ResNet,unwanted column,numeric column,estimator1 parameter,augmentation,augmentation function call,test set,model initialization,auxiliary data set,auxiliary function calls
524,"jc7483, zl1596",rossmann-store-sales,https://www.kaggle.com/c/rossmann-store-sales,12/14/15 23:59,39.55MB,TRUE,FALSE,FALSE,FALSE,table,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,text/csv,[0; Store;integer;1; DayOfWeek;categorical;2; Date;categorical;3; Sales;integer;4; Customers;integer;5; Open;categorical;6; Promo;categorical;7; StateHoliday;categorical;8; SchoolHoliday;categorical],,regression,univariate,general score,3,Sales,FALSE,,"predict 6 weeks of daily sales for 1,115 stores located across Germany","date/time transformation, drop features & entries","[""train=train[train['Sales'] > 0]"", ""train['Date']=pd.to_datetime(train['Date'])"", ""train['month']=train['Date'].dt.month"", ""train['year']=train['Date'].dt.year"", ""train['Store']=pd.to_numeric(train['Store'])""]", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," on=['Store'])"""", ""train=transform(train)""""""""train=transform(train)""""train=transform(train)"""," test=transform(test)""""""""test=transform(test)""""test=transform(test)"""," train['logSales']=pd.to_numeric(np.log(train['Sales']))""""""""train['logSales']=pd.to_numeric(np.log(train['Sales']))""""train['logSales']=pd.to_numeric(np.log(train['Sales']))"""," test['logSales']=0""]""""""train=train[train['Sales'] > 0]""""""""test['logSales']=0""]""""""train=train[train['Sales'] > 0]""""test['logSales']=0""]""""""train=train[train['Sales'] > 0]""""est['logSales']=0""]""""""train=train[t""""st['logSales']=0"""""""""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," on=['Store'])"""", ""train=transform(train)""""""""train=transform(train)""""train=transform(train)""","[""RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)""]"," train['logSales']=pd.to_numeric(np.log(train['Sales']))""""""""train['logSales']=pd.to_numeric(np.log(train['Sales']))""""train['logSales']=pd.to_numeric(np.log(train['Sales']))"""," test['logSales']=0""""""train=train[train['Sales'] > 0]""""""""test['logSales']=0""""""train=train[train['Sales'] > 0]""""test['logSales']=0""""""train=train[train['Sales'] > 0]""""est['logSales']=0""""""train=train[t""""st['logSales']="""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store,mean square error," test=transform(test)""""""""test=transform(test)""""test=transform(test)"""," train['logSales']=pd.to_numeric(np.log(train['Sales']))""""""""train['logSales']=pd.to_numeric(np.log(train['Sales']))""""train['logSales']=pd.to_numeric(np.log(train['Sales']))"""," test['logSales']=0""""""rain=train[train['Sales'] > 0]""""""""test['logSales']=0""""""rain=train[train['Sales'] > 0]""""test['logSales']=0""""""rain=train[train['Sales'] > 0]""""est['logSales']=0""""""rain=train[t""""st['logSales']"""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," on=['Store'])"""", ""train=transform(train)""""""""train=transform(train)""""train=transform(train)"""," test=transform(test)""""""""test=transform(test)""""test=transform(test)"""," train['logSales']=pd.to_numeric(np.log(train['S""""ain=train[train['Sales'] > 0]""""""""train['logSales']=pd.to_numeric(np.log(train['S""""ain=train[train['Sales'] > 0]""""train['logSales']=pd.to_numeric(np.log(train['S""""ain=train[train['Sales'] > 0]""""rain['logSales']=pd.to_numeric"""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," on=['Store'])"""", ""train=transform(train)""""""""train=transform(train)""""train=transform(train)"""," test=transform(test)""""""""test=transform(test)""""test=transform(test)"""," train['logSales']""""in=train[train['Sales'] > 0]""""""""train['logSales']""""in=train[train['Sales'] > 0]""""train['logSales']""""in=train[train['Sales'] > 0]""""rain['logSales']""""in=train[tr""""ain['logSale"""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," on=['Store'])"""", ""train=transform(train)""""""""train=transform(train)""""train=transform(train)"""," test=transfo""""n=train[train['Sales'] > 0]""""""""test=transfo""""n=train[train['Sales'] > 0]""""test=transfo""""n=train[train['Sales'] > 0]""""est=transfo""""n=train[train['""""st=transfo""""n=tr""""t=tra"""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," on=['Store'])"""", ""train=tran""""=train[train['Sales'] > 0]""""""""train=tran""""=train[train['Sales'] > 0]""""train=tran""""=train[train['Sales'] > 0]""""rain=tran""""=train[train['Sa""""ain=tran""""=train[""""in=tran"""""""""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""test=pd.merge(test""""""test=pd.merge(tes""""test=pd.merge(tes""", store," ""train[train['Sales'] > 0]""""train[train['Sales'] > 0]""""""train[train['Sales'] > 0]""""train[train['Sales'] > 0]"""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai""", store," on=['Store'])"""", ""t""""rain[train['Sales'] > 0]""""""""t""""rain[train['Sales'] > 0]""""t""""rain[train['Sales'] > 0]""""""""rain[train['Sales'] > 0""""""rain[train['Sales'] > 0""""rain[train['Sales'] > 0"""," train=pd.merge(train""""""train=pd.merge(trai""""train=pd.merge(trai"""," ""ain[train['Sales'] > 0]""""ain[train['Sales'] > 0]""""""ain[train['Sales'] > 0]""""ain[train['Sales'] > 0]""","i"""",,,,,FALSE,FALSE,FALSE,FALSE,FALSE,H2O,randomforestregressor/classifier,decisiontreeclassifier/regressor,H2ORandomForestEstimator(model_id=rf_covType_v1""""""""", ntrees=200, stopping_rounds=2, max_depth = 30, nbins_cats = 1115, score_each_iteration=True," seed=1000000)""2ORandomForestEstimator(model_id=rf_covType_v1""""""seed=1000000)""""2ORandomForestEstimator(model_id=""""""eed=1000000)""""2ORandomForestEstimat""""ed=1000000)""""2ORandomF""""d=1000000)""", ntrees=200, stopping_rounds=2, max_depth = 30,"[""Date""]",,,,,rossmann-store-sales,,"[""store""]","[""train=pd.merge(train, auxiliary[0], on=['Store'])"", ""test=pd.merge(test, auxiliary[0], on=['Store'])""]"